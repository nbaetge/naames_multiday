---
title: "S4_16S"
author: "Nicholas Baetge"
date: "8/14/2020"
output: github_document
---

# Intro

Here, the NAAMES cast 16S sequences from N2S4 are analyzed

```{r message = F, warning = F}
library(tidyverse) 
library(rmarkdown)
library(knitr)
library(readxl)
library(data.table) 
library(scales)
library(patchwork)
library(lubridate)
#stat tests
library(lmtest)
library(lmodel2)
library(rstatix)
library(ggpubr)
#phyloseq
library(phyloseq)
library(RColorBrewer)
library(calecopal)


```

```{r}
custom_theme <- function() {
  theme_test(base_size = 24) %+replace%
    theme(legend.position = "right",
          legend.spacing.x = unit(0.5,"cm"),
          legend.title = element_text(size = 14),
          legend.text = element_text(size = 14),
          legend.background = element_rect(fill = "transparent",colour = NA),
          legend.key = element_rect(fill = "transparent",colour = NA),
          panel.background = element_rect(fill = "transparent",colour = NA),
          plot.background = element_rect(fill = "transparent",colour = NA)) 
}

custom.colors <- c("AT39" = "#377EB8", "AT34" = "#4DAF4A", "AT38" = "#E41A1C", "AT32" = "#FF7F00", "Temperate" = "#A6CEE3", "Subpolar" = "#377EB8", "Subtropical" = "#FB9A99", "GS/Sargasso" = "#E41A1C", "Early Spring" = "#377EB8", "Late Spring" = "#4DAF4A","Early Autumn" = "#E41A1C", "Late Autumn" = "#FF7F00")

levels = c("GS/Sargasso", "Subtropical", "Temperate", "Subpolar",  "AT39-6", "AT34", "AT38", "AT32", "Early Spring", "Late Spring","Early Autumn",   "Late Autumn", "5-75 m", "100-200 m", "300 m", "> 300 m", "0", "1", "2", "3", "5 m", "25 m", "50 m", "75 m", "100 m", "150 m", "200 m" )

odv.colors <- c("#feb483", "#d31f2a", "#ffc000", "#27ab19", "#0db5e6", "#7139fe", "#d16cfa")
```


# Import Data 

```{r}
custom.tab <- readRDS("~/GITHUB/naames_multiday/Output/Custom_ASV_Table.rds") %>% 
  filter(Cruise == "AT34" & Station == 4 & z <= 200) %>% 
  mutate(time = ymd_hms(datetime),
         interv = interval(first(time), time),
         dur = as.duration(interv),
         days = round(as.numeric(dur, "days")),
         eddy = ifelse(Date != "2016-05-27" & Station != 6, "Core", "Outside")) %>% 
  select(Cruise:bcd, eddy, time:days, everything())

sub_ps <- readRDS("~/GITHUB/naames_multiday/Output/phyloseq_obj.rds") %>% 
  subset_samples(Cruise == "AT34" & Station == 4 & z <= 200)

```


## Add new sample data to phyloseq object

```{r}
ctd <-  readRDS("~/GITHUB/naames_multiday/Input/ctd/deriv_naames_ctd.rds") %>%
              select(Cruise, Station, CampCN,  bin_depth, deriv_aou_umol_l, fl_mg_m3, ave_temp_c, ave_sal_psu, beamT_perc, ave_dens_kg_m3) %>% 
              mutate(Cruise = ifelse(Cruise == "AT39", "AT39-6", Cruise)) %>% 
              rename(z = bin_depth,
                     aou = deriv_aou_umol_l,
                     fl = fl_mg_m3,
                     temp = ave_temp_c,
                     sal = ave_sal_psu,
                     density = ave_dens_kg_m3,
                     beamT = beamT_perc) 


npp <- read_rds("~/GITHUB/naames_multiday/Input/Z_resolved_model_NPP.rds") %>% 
  rename(z = depth,
         npp = NPP)

new.sample.tab <- read_rds("~/GITHUB/naames_multiday/Input/export_ms/processed_bf.8.2020.rds") %>% 
  mutate(Station = ifelse(Station == "1A", 0, Station)) %>% 
  mutate_at(vars(Station), as.numeric) %>% 
  select(Cruise:CampCN, Target_Z, DNA_ID) %>% 
  drop_na(DNA_ID) %>% 
  rename(z = Target_Z) %>% 
  left_join(., read_rds("~/GITHUB/naames_multiday/Output/processed_data.rds") %>%
              select(Cruise, Station, Date,  CampCN, mld, z,  doc, n, phyc, bc, bcd, tdaa, Asp:Lys ) %>% 
              distinct() %>% 
              mutate_at(vars(phyc:bcd, tdaa:Lys), function(x)(x/10^3))) %>% 
  mutate(sample_depths = ifelse(z < 100, "5-75 m", "100-200 m"),
         sample_depths = ifelse(z == 300, "300 m", sample_depths),
         sample_depths = ifelse(z > 300, "> 300 m", sample_depths)) %>% 
  select(Cruise:z, sample_depths, everything()) %>% 
  left_join(., ctd) %>% 
  left_join(., npp) %>% 
  filter(Cruise == "AT34" & Station == 4 & z <= 200) %>% 
  mutate(time = ymd_hms(datetime),
         interv = interval(first(time), time),
         dur = as.duration(interv),
         days = round(as.numeric(dur, "days")),
         eddy = ifelse(Date != "2016-05-27" & Station != 6, "Core", "Outside")) %>% 
  select(Cruise:npp, eddy,  time:days) %>% 
  column_to_rownames(var = "DNA_ID") 

sample_data(sub_ps) <- new.sample.tab

```



# Beta Diversity

Beta diversity involves calculating metrics such as distances or dissimilarities based on pairwise comparisons of samples – they don’t exist for a single sample, but rather only as metrics that relate samples to each other. i.e. beta diversity =  patterns in community structure between samples

Since differences in sampling depths between samples can influence distance/dissimilarity metrics, we first need to somehow normalize the read depth across our samples. 

### Subsample

We will rarefy (random subsample with replacement) the read depth of the samples first (scale to the smallest library size). This is consistent with the analysis done by Bolanos et al, in prep.

[Case for not subsampling]( https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1003531)

[Response blog for subsampling](https://www.polarmicrobes.org/how-i-learned-to-stop-worrying-and-love-subsampling-rarifying/)

Read depth is an artifact of a machine made by a company in San Diego, not anything about your samples or their biology. It is totally artifactual, and controlling for artifacts is critical in science. Subsampling randomly is the simplest way to control for this, and the question is whether this is the "best" way of controlling for it. See links above for alternative arguments about what the best way of controlling for this artifact is. 

A strong reason to subsample is to standardize effort. The bottom line is that in all experimental design you should not be comparing things to which you devote different effort in resolution. For instance, you don't sample one site once a week and another once a month if you want to compare the dynamics between the sites. You standardize effort.

With that said, the bigger your differential in mean (or median) read depth (reads/sample) between pre- and post-subsampling, the greater the "effect" on beta diversity. 

Examples:

- means reads before = 40k, mean reads after = 1k, big effect.
- mean reads before = 40k, mean reads after = 20k, small effect.
- mean reads before = 2k, mean reads after = 1k, small effect.


We will subsample  three ways (depths of 5000, minimum read depth of all samples, and no subsampling) and compare resulting patterns, inluding:

- How environmental patterns in alpha diversity change
- How absolute alpha diversity changes
- How patterns among samples change (compare distance matrices, or compare PERMANOVA results)


## Sample Summary

We will first look at the distribution of read counts from our samples

```{r echo = FALSE, warning = FALSE, message = FALSE, fig.height = 6, fig.width = 12, fig.align = "center"}

# Make a data frame with a column for the read counts of each sample
sample_sum_df <- data.frame(sum = sample_sums(sub_ps))

# Histogram of sample read counts
ggplot(sample_sum_df, aes(x = sum)) + 
  geom_histogram(color = "black", fill = "#377EB8", binwidth = 2500) +
  ggtitle("Distribution of sample sequencing depth") + 
  xlab("Read counts") +
  theme(axis.title.y = element_blank()) +
  custom_theme()
```


```{r}
#mean read depth before and after random subsampling, larger differential = greater "effect" on beta diversity
mean(sample_sums(sub_ps)) #120,302
min(sample_sums(sub_ps)) #30,887

ps_min <- rarefy_even_depth(sub_ps, sample.size = min(sample_sums(sub_ps)), rngseed = 532898)


ps_10k = rarefy_even_depth(sub_ps, sample.size = 10000, rngseed = 532898)

```

## Unconstrained Ordination

One of the best exploratory analyses for amplicon data is unconstrained ordinations. Here we will look at ordinations of our full community samples. 


### PCoA

```{r}
pcoa_all <- ordinate(sub_ps, method = "PCoA", distance = "bray")
pcoa_min <- ordinate(ps_min, method = "PCoA", distance = "bray")
pcoa_10k <- ordinate(ps_10k, method = "PCoA", distance = "bray")

```


```{r echo = FALSE, warning = FALSE, message = FALSE, fig.height = 8, fig.width = 10, fig.align = "center"}

pcoa.plot <- plot_ordination(sub_ps, pcoa_all,  title = "Bray Curtis PCoA - No Subsampling") +
  geom_point(aes(fill = Date, shape = factor(sample_depths, levels = levels)), color = "black", alpha = 0.6, stroke = 2, size = 4) +
  scale_shape_manual(values = c(21, 22, 23)) +
  scale_fill_date(low = "#0db5e6",  high = "#d31f2a") +
  custom_theme()  
#removing one of the plotting layers (there are points within points)
pcoa.plot$layers <- pcoa.plot$layers[-1]

pcoa.plot + 
  facet_grid(rows = "eddy") +
   guides(fill = guide_colourbar(title = "", barheight = 10, barwidth = 2, frame.colour = "black", frame.linewidth = 2,ticks.colour = "black", ticks.linewidth = 1), shape = guide_legend(title = "Sample Depths"))
```

```{r echo = FALSE, warning = FALSE, message = FALSE, fig.height = 8, fig.width = 10, fig.align = "center"}

pcoa.plot <- plot_ordination(ps_min, pcoa_min) +
  geom_point(aes(fill = Date, shape = factor(sample_depths, levels = levels)), color = "black", alpha = 0.6, stroke = 2, size = 4) +
  scale_shape_manual(values = c(21, 22, 23)) +
  scale_fill_date(low = "#0db5e6",  high = "#d31f2a") +
  custom_theme()  
#removing one of the plotting layers (there are points within points)
pcoa.plot$layers <- pcoa.plot$layers[-1]

pcoa.plot + 
  facet_grid(rows = "eddy") +
   guides(fill = guide_colourbar(title = "", barheight = 10, barwidth = 2, frame.colour = "black", frame.linewidth = 2,ticks.colour = "black", ticks.linewidth = 1), shape = guide_legend(title = "Sample Depths"))
```

```{r echo = FALSE, warning = FALSE, message = FALSE, fig.height = 8, fig.width = 10, fig.align = "center"}

pcoa.plot <- plot_ordination(ps_10k, pcoa_10k,  title = "Bray Curtis PCoA - Subsampling 10k Reads") +
   geom_point(aes(fill = Date, shape = factor(sample_depths, levels = levels)), color = "black", alpha = 0.6, stroke = 2, size = 4) +
  scale_shape_manual(values = c(21, 22, 23)) +
  scale_fill_date(low = "#0db5e6",  high = "#d31f2a") +
  custom_theme()  
#removing one of the plotting layers (there are points within points)
pcoa.plot$layers <- pcoa.plot$layers[-1]

pcoa.plot + 
  facet_grid(rows = "eddy") +
  guides(fill = guide_colourbar(title = "", barheight = 10, barwidth = 2, frame.colour = "black", frame.linewidth = 2,ticks.colour = "black", ticks.linewidth = 1), shape = guide_legend(title = "Sample Depths"))
```

### NMDS

Let’s try an NMDS instead. For NMDS plots it’s important to set a seed since the starting positions of samples in the alogrithm is random.

Important: if you calculate your bray-curtis distance metric “in-line” it will perform a square root transformation and Wisconsin double standardization. If you don’t want this, you can calculate your bray-curtis distance separately


```{r}
set.seed(1)

# Ordinate
nmds_all <- ordinate(sub_ps, method = "NMDS",  distance = "bray", trymax = 500) # stress = 0.08
nmds_min <- ordinate(ps_min, method = "NMDS",  distance = "bray", trymax = 500) # stress = 0.08, no convergence i.e. two axes not sufficient to view data
nmds_10k <- ordinate(ps_10k, method = "NMDS",  distance = "bray", trymax = 500) # stress = 0.09, no convergence


```


```{r echo = FALSE, warning = FALSE, message = FALSE, fig.height = 8, fig.width = 10, fig.align = "center"}

nmds.plot <- plot_ordination(sub_ps, nmds_all,  title = "NMDS - No Subsampling") +
  geom_point(aes(fill = Date, shape = factor(sample_depths, levels = levels)), color = "black", alpha = 0.6, stroke = 2, size = 4) +
  scale_shape_manual(values = c(21, 22, 23)) +
  scale_fill_date(low = "#0db5e6",  high = "#d31f2a") +
  custom_theme()  
#removing one of the plotting layers (there are points within points)
nmds.plot$layers <- nmds.plot$layers[-1]

nmds.plot + 
  facet_grid(rows = "eddy") +
  guides(fill = guide_colourbar(title = "", barheight = 10, barwidth = 2, frame.colour = "black", frame.linewidth = 2,ticks.colour = "black", ticks.linewidth = 1), shape = guide_legend(title = "Sample Depths"))
```

```{r echo = FALSE, warning = FALSE, message = FALSE, fig.height = 8, fig.width = 10, fig.align = "center"}

nmds.plot <- plot_ordination(ps_min, nmds_min) +
   geom_point(aes(fill = Date, shape = factor(sample_depths, levels = levels)), color = "black", alpha = 0.6, stroke = 2, size = 4) +
  scale_shape_manual(values = c(21, 22, 23)) +
  scale_fill_date(low = "#0db5e6",  high = "#d31f2a") +
  custom_theme()  
#removing one of the plotting layers (there are points within points)
nmds.plot$layers <- nmds.plot$layers[-1]

nmds.plot + 
  facet_grid(rows = "eddy") +
  guides(fill = guide_colourbar(title = "", barheight = 10, barwidth = 2, frame.colour = "black", frame.linewidth = 2,ticks.colour = "black", ticks.linewidth = 1), shape = guide_legend(title = "Sample Depths"))
```

```{r echo = FALSE, warning = FALSE, message = FALSE, fig.height = 8, fig.width = 10, fig.align = "center"}

nmds.plot <- plot_ordination(ps_10k, nmds_10k,  title = "NMDS - Subsampling 10k Reads") +
  geom_point(aes(fill = Date, shape = factor(sample_depths, levels = levels)), color = "black", alpha = 0.6, stroke = 2, size = 4) +
  scale_shape_manual(values = c(21, 22, 23)) +
  scale_fill_date(low = "#0db5e6",  high = "#d31f2a") +
  custom_theme()  
#removing one of the plotting layers (there are points within points)
nmds.plot$layers <- nmds.plot$layers[-1]

nmds.plot + 
  facet_grid(rows = "eddy") +
  guides(fill = guide_colourbar(title = "", barheight = 10, barwidth = 2, frame.colour = "black", frame.linewidth = 2,ticks.colour = "black", ticks.linewidth = 1), shape = guide_legend(title = "Sample Depths"))
```


NMDS plots attempt to show ordinal distances between samples as accurately as possible in two dimensions. It is important to report the stress of these plots, because a high stress value means that the algorithm had a hard time representing the distances between samples in 2 dimensions. The stress of all the plots was good (generally anything below 0.2 is considered acceptable). 

## Constrained Ordination

Above we used unconstrained ordinations (PCoA, NMDS) to show relationships between samples in low dimensions. We can use a constrained ordination to see how environmental variables are associated with these changes in community composition. We constrain the ordination axes to linear combinations of environmental variables. We then plot the environmental scores onto the ordination

```{r}
# Remove data points with missing metadata
ps_all_na.rm <- sub_ps %>%
  subset_samples(!is.na(mld) & !is.na(npp) & !is.na(doc) & !is.na(n) & !is.na(bc) & !is.na(bcd) & !is.na(aou) & !is.na(fl) & !is.na(sal) & !is.na(temp) & !is.na(density) & !is.na(beamT) )

ps_min_na.rm <- ps_min %>%
  subset_samples(!is.na(mld) & !is.na(npp) & !is.na(doc) & !is.na(n) & !is.na(bc) & !is.na(bcd) & !is.na(aou) & !is.na(fl) & !is.na(sal) & !is.na(temp) & !is.na(density) & !is.na(beamT) )

ps_10k_na.rm <- ps_10k %>%
  subset_samples(!is.na(mld) & !is.na(npp) & !is.na(doc) & !is.na(n) & !is.na(bc) & !is.na(bcd) & !is.na(aou) & !is.na(fl) & !is.na(sal) & !is.na(temp) & !is.na(density) & !is.na(beamT) )


bray_all <- phyloseq::distance(ps_all_na.rm, method = "bray")
bray_min <- phyloseq::distance(ps_min_na.rm, method = "bray")
bray_10k <- phyloseq::distance(ps_10k_na.rm, method = "bray")

# CAP ordinate
cap_ord_all <- ordinate(ps_all_na.rm, method = "CAP", distance = bray_all, formula = ~ mld + doc + n  + bcd + aou + fl + sal + bc + beamT +  npp + temp + days + z + density )
cap_ord_min <- ordinate(ps_min_na.rm, method = "CAP", distance = bray_min, formula = ~ mld + doc + n  + bcd + aou + fl + sal + bc + beamT +  npp + temp + days + z + density )
cap_ord_10k <- ordinate(ps_10k_na.rm, method = "CAP", distance = bray_10k, formula = ~ mld + doc + n  + bcd + aou + fl + sal + bc + beamT +  npp + temp + days + z + density )
```



```{r echo = FALSE, warning = FALSE, message = FALSE, fig.height = 8, fig.width = 10, fig.align = "center"}

# CAP plot
cap.plot <- plot_ordination(ps_all_na.rm, ordination = cap_ord_all, axes = c(1,2)) +
 geom_point(aes(fill = Date, shape = factor(sample_depths, levels = levels)), color = "black", alpha = 0.6, stroke = 2, size = 4) +
  scale_shape_manual(values = c(21, 22, 23)) +
  scale_fill_date(low = "#0db5e6",  high = "#d31f2a") +
  custom_theme()  +
  facet_grid(rows = "eddy") +
  guides(fill = guide_colourbar(title = "", barheight = 10, barwidth = 2, frame.colour = "black", frame.linewidth = 2,ticks.colour = "black", ticks.linewidth = 1), shape = guide_legend(title = "Sample Depths")) +
  ggtitle("No Subsampling")
#removing one of the plotting layers (there are points within points)

cap.plot$layers <- cap.plot$layers[-1]



# Now add the environmental variables as arrows
arrowmat <- vegan::scores(cap_ord_all, display = "bp")

# Add labels, make a data.frame
arrowdf <- data.frame(labels = rownames(arrowmat), arrowmat)

# Define the arrow aesthetic mapping
arrow_map <- aes(xend = CAP1, 
    yend = CAP2, 
    x = 0, 
    y = 0, 
    shape = NULL, 
    color = NULL, 
    label = labels)

label_map <- aes(x = 1.3 * CAP1, 
    y = 1.3 * CAP2, 
    shape = NULL, 
    color = NULL, 
    label = labels)

arrowhead = arrow(length = unit(0.02, "npc"))

# Make a new graphic
cap.plot + 
  geom_segment(
    mapping = arrow_map, 
    size = .5, 
    data = arrowdf, 
    color = "gray", 
    arrow = arrowhead
  ) + 
  geom_text(
    mapping = label_map, 
    size = 4,  
    data = arrowdf, 
    show.legend = FALSE
  )

```


```{r echo = FALSE, warning = FALSE, message = FALSE, fig.height = 8, fig.width = 10, fig.align = "center"}

# CAP plot
cap.plot <- plot_ordination(ps_min_na.rm, ordination = cap_ord_min, axes = c(1,2)) +
   geom_point(aes(fill = Date, shape = factor(sample_depths, levels = levels)), color = "black", alpha = 0.6, stroke = 2, size = 4) +
  scale_shape_manual(values = c(21, 22, 23)) +
  scale_fill_date(low = "#0db5e6",  high = "#d31f2a") +
  custom_theme()  +
  facet_grid(rows = "eddy") +
  guides(fill = guide_colourbar(title = "", barheight = 10, barwidth = 2, frame.colour = "black", frame.linewidth = 2,ticks.colour = "black", ticks.linewidth = 1), shape = guide_legend(title = "Sample Depths")) 
  #ggtitle("Subsampling Min Read Depth")
#removing one of the plotting layers (there are points within points)

cap.plot$layers <- cap.plot$layers[-1]



# Now add the environmental variables as arrows
arrowmat <- vegan::scores(cap_ord_min, display = "bp")

# Add labels, make a data.frame
arrowdf <- data.frame(labels = rownames(arrowmat), arrowmat)

# Define the arrow aesthetic mapping
arrow_map <- aes(xend = CAP1, 
    yend = CAP2, 
    x = 0, 
    y = 0, 
    shape = NULL, 
    color = NULL, 
    label = labels)

label_map <- aes(x = 1.3 * CAP1, 
    y = 1.3 * CAP2, 
    shape = NULL, 
    color = NULL, 
    label = labels)

arrowhead = arrow(length = unit(0.02, "npc"))

# Make a new graphic
cap.plot + 
  geom_segment(
    mapping = arrow_map, 
    size = .5, 
    data = arrowdf, 
    color = "gray", 
    arrow = arrowhead
  ) + 
  geom_text(
    mapping = label_map, 
    size = 4,  
    data = arrowdf, 
    show.legend = FALSE
  )

```


```{r echo = FALSE, warning = FALSE, message = FALSE, fig.height = 8, fig.width = 10, fig.align = "center"}

# CAP plot
cap.plot <- plot_ordination(ps_10k_na.rm, ordination = cap_ord_10k, axes = c(1,2)) +
  geom_point(aes(fill = Date, shape = factor(sample_depths, levels = levels)), color = "black", alpha = 0.6, stroke = 2, size = 4) +
  scale_shape_manual(values = c(21, 22, 23)) +
  scale_fill_date(low = "#0db5e6",  high = "#d31f2a") +
  custom_theme()  +
  facet_grid(rows = "eddy") +
  guides(fill = guide_colourbar(title = "", barheight = 10, barwidth = 2, frame.colour = "black", frame.linewidth = 2,ticks.colour = "black", ticks.linewidth = 1), shape = guide_legend(title = "Sample Depths")) +
  ggtitle("Subsampling 10k Reads")
#removing one of the plotting layers (there are points within points)

cap.plot$layers <- cap.plot$layers[-1]



# Now add the environmental variables as arrows
arrowmat <- vegan::scores(cap_ord_10k, display = "bp")

# Add labels, make a data.frame
arrowdf <- data.frame(labels = rownames(arrowmat), arrowmat)

# Define the arrow aesthetic mapping
arrow_map <- aes(xend = CAP1, 
    yend = CAP2, 
    x = 0, 
    y = 0, 
    shape = NULL, 
    color = NULL, 
    label = labels)

label_map <- aes(x = 1.3 * CAP1, 
    y = 1.3 * CAP2, 
    shape = NULL, 
    color = NULL, 
    label = labels)

arrowhead = arrow(length = unit(0.02, "npc"))

# Make a new graphic
cap.plot + 
  geom_segment(
    mapping = arrow_map, 
    size = .5, 
    data = arrowdf, 
    color = "gray", 
    arrow = arrowhead
  ) + 
  geom_text(
    mapping = label_map, 
    size = 4,  
    data = arrowdf, 
    show.legend = FALSE
  )

```

Do a permutational ANOVA on constrained axes used in ordination

```{r}
anova(cap_ord_all) 
```

```{r}
anova(cap_ord_min) 
```

```{r}
anova(cap_ord_10k) 
```


# Betadisper and permutational ANOVA

Above, we performed beta diversity analyses on Bray-Curtis distances on rarefied datasets that were then visualized using PCoA, NMDS, and CAP. We can test if there are statistically significant differences between sample groups using the betadisper and adonis functions of the vegan package. Betadisper tests whether two or more groups are homogeneously dispersed in relation to their species in studied samples. This test can be done to see if one group has more compositional variance than another. Moreover, homogeneity of dispersion among groups is very advisable to have if you want to test if two or more groups have different compositions, which is tested by adonis.

##  Phyloseq to DESeq, distance matrix

To be able to run the stats, we first have to create a distance matrix from our data. We'll use the DESeq package to do so.

```{r message = F, warning = F}
library(DESeq2)
library(vegan)
```


```{r}

deseq_counts <- phyloseq_to_deseq2(ps_min, design = ~days) #the design argument is required but doesn't matter here
deseq_count_tab <- assay(deseq_counts) #extract the read count matrix

```

We'll calculate euclidean distances

```{r}

#We can subset our data if we want to and calculate distances/run stats for only a subset of the group. The code below shows how, but we're not actually going to subset anything
subset_sample_IDs <-  row.names(new.sample.tab)[between(new.sample.tab$z, 0, 200)]

euc_dist <- dist(t(deseq_count_tab[ , colnames(deseq_count_tab) %in% subset_sample_IDs]))

sample_info_tab <- new.sample.tab[row.names(new.sample.tab) %in% subset_sample_IDs, ]

```

Betadisper first calculates the average distance of group members to the group centroid in multivariate space (generated by a distance matrix).

Our first question is: Is the community composition from 5-200 m different between each day of the station occupation?

In the function below: we are using the distance matrix to calculate the multivariate dispersions (variances; average distance to centroids). We then use group dispersions to perform an ANOVA test.

```{r}
anova(betadisper(euc_dist, sample_info_tab$Date)) 
```

The ANOVA’s p-value is not significant meaning that group dispersions are homogenous (“Null hypothesis of no difference in dispersion between groups”)

Adonis analyzes and partitions sums of squares using distance matrices. It can be seen as an ANOVA using distance matrices (analogous to MANOVA – multivariate analysis of variance). Therefore, it is used to test if two or more groups have similar compositions.

```{r}
adonis(euc_dist~sample_info_tab$Date)
```

Our results indicate that the community between each day has a highly significantly different composition (p < 0.01). 

**So our groups (days) present homogeneity among group dispersions (compositions vary similarly) while having significantly different compositions.**

What about at each depth horizon (5-75 m, 100 - 200 m)?

### Surface 75 m

```{r}
#We can subset our data if we want to and calculate distances/run stats for only a subset of the group. The code below shows how, but we're not actually going to subset anything
surf_sample_IDs <-  row.names(new.sample.tab)[between(new.sample.tab$z, 0, 75)]

surf_euc_dist <- dist(t(deseq_count_tab[ , colnames(deseq_count_tab) %in% surf_sample_IDs]))

surf_sample_info_tab <- new.sample.tab[row.names(new.sample.tab) %in% surf_sample_IDs, ]

```

```{r}
anova(betadisper(surf_euc_dist, surf_sample_info_tab$Date)) 
```

```{r}
adonis(surf_euc_dist~surf_sample_info_tab$Date)
```

**Our groups (days) in the surface 75 m present homogeneity among group dispersions (compositions vary similarly) and do not have significantly different compositions.**


### 100 - 200 m

```{r}
#We can subset our data if we want to and calculate distances/run stats for only a subset of the group. The code below shows how, but we're not actually going to subset anything
deep_sample_IDs <-  row.names(new.sample.tab)[between(new.sample.tab$z, 100, 200)]

deep_euc_dist <- dist(t(deseq_count_tab[ , colnames(deseq_count_tab) %in% deep_sample_IDs]))

deep_sample_info_tab <- new.sample.tab[row.names(new.sample.tab) %in% deep_sample_IDs, ]

```

```{r}
anova(betadisper(deep_euc_dist, deep_sample_info_tab$Date)) 
```

```{r}
adonis(deep_euc_dist~deep_sample_info_tab$Date)
```

**Our groups (days) in the 100-200 m depth horizon present homogeneity among group dispersions (compositions vary similarly) and have significantly different compositions.**


# Alpha Diversity

Generating estimates of alpha diversity for microbial communities isn't hard, but generating *trustworthy* estimates is hard [problematic](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC93182/) no matter what you do.

We will use the subsampled library, which retains estimates of the species abundance of the real population while standardizing sampling effort.

[subsampling  and alpha diversity paper](https://www.frontiersin.org/articles/10.3389/fmicb.2019.02407/full)

[Chao1: nonparametric estimation of minimum community richness](https://www.jstor.org/stable/4615964?seq=1#metadata_info_tab_contents) 

 Difference in the alpha diversity indexes among conditions were tested using Kruskal-Wallis test followed by pairwise Wilcoxon tests; p < 0.05 was considered the threshold significance for a difference between conditions.

```{r}

richness <- estimate_richness(ps_min, measures = c("Chao1", "Shannon")) %>% 
  rownames_to_column(., var = "DNA_ID") %>% 
  mutate_at(vars(DNA_ID), str_replace_all, pattern = "NAAMES2.", "NAAMES2-")

```

Let’s add the sample metadata into this dataframe 

```{r}
alphadiv <- left_join(richness, new.sample.tab %>% rownames_to_column(., var = "DNA_ID")) 
```



```{r echo = FALSE, warning = FALSE, message = FALSE, fig.height = 8, fig.width = 10, fig.align = "center"}

my_comparisons <- list( c("24", "25"), c("24", "26"), c("24", "27"), c("25","26"), c("25", "27"), c("26","27") ) 

alpha.plot <- alphadiv %>% 
  mutate(z_label = paste(z, "m"),
         day = day(Date)) %>% 
  select(day, z, z_label, sample_depths, Chao1, Shannon) %>% 
  pivot_longer(.,  cols = c(Chao1,  Shannon), names_to = "measure", values_to = "est" ) %>% 
  left_join(., alphadiv %>%  mutate(z_label = paste(z, "m"), day = day(Date)) %>% 
              select(day, z, z_label, se.chao1)) %>% 
  mutate(se.chao1 = ifelse(measure == "Chao1", se.chao1, NA)) %>%
  ggboxplot(., x = "day", y = "est", 
            order = c("24", "25", "26", "27"),
            xlab = expression(italic(paste("May"))), 
            ylab = expression(italic(paste("Alpha Diversity Measure"))),
            add = "jitter",
            width = 0.5,
            ggtheme = custom_theme()) +  
  stat_compare_means(comparisons = my_comparisons, 
                     label = "p.signif",
                     step.increase = 0.25) +
  stat_compare_means(label.y = 5.5) +
  facet_grid(measure~factor(sample_depths, levels = levels), scales = "free") 
```
```{r echo = FALSE, warning = FALSE, message = FALSE, fig.height = 6, fig.width = 8, fig.align = "center", warning = FALSE}
chao.plot <- alphadiv %>% 
  ggplot(aes(x = z, y = Chao1, group = interaction(Date, CampCN))) +
   geom_errorbar(aes(ymin = Chao1 - se.chao1, ymax = Chao1 + se.chao1, color = Date), width = 3, alpha = 0.7) +
  geom_line(aes(linetype = eddy, color = Date), size = 0.7) +
  geom_point(aes(shape = eddy, fill = Date), size = 6, color = "black", stroke = 1, alpha = 0.7) + 
  labs(x = expression(italic(paste("Depth, m"))), y = expression(italic(paste("Chao1"))), colour = "", fill = "", linetype = "Eddy Location", shape = "Eddy Location") +
  scale_x_reverse(breaks = pretty_breaks(), expand = c(0,0)) +
  coord_flip() +
  scale_y_continuous(expand = c(0,0)) +
  scale_shape_manual(values = c("Core" = 21, "Outside" = 24)) +
  scale_fill_date(low = "#0db5e6", high = "#d31f2a") +
  scale_color_date(low = "#0db5e6", high = "#d31f2a") +
  guides(fill = guide_colourbar(barheight = 20, barwidth = 2, frame.colour = "black", frame.linewidth = 2,ticks.colour = "black", ticks.linewidth = 1), color = F) +
  custom_theme() +
  theme(panel.spacing.x = unit(1, "cm"),
        axis.text.x = element_text(angle = 0),
        legend.key.size = unit(1, "cm"))
```

```{r echo = FALSE, warning = FALSE, message = FALSE, fig.height = 6, fig.width = 8, fig.align = "center", warning = FALSE}
shannon.plot <-  alphadiv %>% 
  ggplot(aes(x = z, y = Shannon, group = interaction(Date, CampCN))) +
  geom_line(aes(linetype = eddy, color = Date), size = 0.7) +
  geom_point(aes(shape = eddy, fill = Date), size = 6, color = "black", stroke = 1, alpha = 0.7) + 
  labs(x = expression(italic(paste("Depth, m"))), y = expression(italic(paste("Shannon"))), colour = "", fill = "", linetype = "Eddy Location", shape = "Eddy Location") +
  scale_x_reverse(breaks = pretty_breaks(), expand = c(0,0)) +
  coord_flip() +
  scale_y_continuous(expand = c(0,0)) +
  scale_shape_manual(values = c("Core" = 21, "Outside" = 24)) +
  scale_fill_date(low = "#0db5e6", high = "#d31f2a") +
  scale_color_date(low = "#0db5e6", high = "#d31f2a") +
  guides(fill = F, color = F, shape = F, linetype = F) +
  custom_theme() +
  theme(panel.spacing.x = unit(1, "cm"),
        axis.text.x = element_text(angle = 0),
        legend.key.size = unit(1, "cm"))
```

```{r echo = FALSE, warning = FALSE, message = FALSE, fig.height = 20, fig.width = 18, fig.align = "center"}
patchwork <- alpha.plot / (chao.plot + shannon.plot)

patchwork +  
  plot_layout(guides = 'collect') +
  plot_annotation(tag_levels = "a") &
  theme(plot.tag = element_text(size = 22)) 
```


These are not interpretable as “real” numbers of anything (due to the nature of amplicon data), but they can still be useful as relative metrics of comparison. If Chao1 richness goes up, but Shannon diversity goes down, it indicates that the sample may have more ASVs but is dominated by a few of them. 

**In this case, though our groups (days) showed significantly different compositions, there weren't significant changes in overall diversity or richness. So it seems like the community shift wasn't driven by the emergence or disappearance of new ASVs, but rather the change in relative proportion of existing ASVs. With that said, our grouping of sample depths and box plots likely masks dynamics that we can kind of see in the depth profile **

# DESeq2

Which taxa were important? Which taxa were contributing to thechange in community compositon?

**Note: Recovered 16S rRNA gene copy numbers do not equal organism abundance.**

That said, we can perform differential abundance testing to test for which representative sequences have significantly different copy-number counts between samples using the DESeq1 package, which allows testing for differential abundance using negative binomial generalized linear models.

```{r}
# if (!requireNamespace("BiocManager", quietly = TRUE))
#     install.packages("BiocManager")
# 
# BiocManager::install("DESeq2")
```


```{r}
deseq <-  DESeq(deseq_counts, test = "Wald", fitType = "local")
```

We can save the results to a table with the DESeq results command, retaining all results for further exploration (i.e., cooksCutoff = F). Significant shifts are identified as those with a Benjamini–Hochberg adjusted p-value < 0.05

```{r}
res <- results(deseq, cooksCutoff = FALSE)
alpha <- 0.05
sigtab <-  res[which(res$padj < alpha), ]
sigtab <-  cbind(as(sigtab, "data.frame"), as(tax_table(ps_min)[rownames(sigtab), ], "matrix"))
head(sigtab)
```

```{r}
dim(sigtab)
```

```{r echo = FALSE, warning = FALSE, message = FALSE, fig.height = 8, fig.width = 14, fig.align = "center"}

order.colors <- c("Alphaproteobacteria/Rhodobacterales" = "#026779",
                  "Alphaproteobacteria/SAR11_clade" = "#0FB2D3",
                  "Deltaproteobacteria/Bdellovibrionales" = "#83932D","Deltaproteobacteria/SAR324_clade(Marine_group_B)" = "#516238", "Deltaproteobacteria/Sh765B-TzT-29" = "#AEC96F", "Gammaproteobacteria/Alteromonadales" = "#D3105C", "Gammaproteobacteria/Cellvibrionales" = "#E4B3E2" ,  "Gammaproteobacteria/Oceanospirillales" = "#ac181d",  
                  "Flavobacteriia/Flavobacteriales" = "#F19B34",
                  "Sphingobacteriia/Sphingobacteriales" = "#FDD989",  "NA/NA" = "#D9E4DC" )

order.levels <- c("Alphaproteobacteria/Rhodobacterales",
                  "Alphaproteobacteria/SAR11_clade",
                  "Deltaproteobacteria/Bdellovibrionales","Deltaproteobacteria/SAR324_clade(Marine_group_B)", "Deltaproteobacteria/Sh765B-TzT-29", "Gammaproteobacteria/Alteromonadales", "Gammaproteobacteria/Cellvibrionales",  "Gammaproteobacteria/Oceanospirillales",  
                  "Flavobacteriia/Flavobacteriales",
                  "Sphingobacteriia/Sphingobacteriales" ,  "NA/NA")


all_log2 <- sigtab %>% 
  mutate(family_genus = paste(Family, Genus, sep = "/" ),
         class_order = paste(Class, Order, sep = "/")) %>% 
  ggplot(., aes(x = family_genus, y = log2FoldChange, fill =
                  factor(class_order, levels = order.levels), shape = Phylum)) + 
  geom_point(color = "black",  alpha = 0.7, size = 6) + 
  custom_theme() +
  scale_fill_manual(values = order.colors) +
  scale_shape_manual(values = c("Proteobacteria" = 21, "Bacteroidetes" = 22, "Marinimicrobia_(SAR406_clade)" = 24)) +
  geom_hline(yintercept = 0, linetype = 2) +
  labs(x = expression(italic("")), y = expression(italic("log2 Fold Change")), fill = "Class/Order") +
  theme(axis.text.x = element_text(angle = -15, hjust = 0, vjust = 0.5)) +
  guides(fill = guide_legend(override.aes = list(shape = 21))) +
  ggtitle("All Depths")
```


### Surface 75 m

```{r}

surf_ps_min <- subset_samples(ps_min, between(z, 0, 75))
surf_deseq_counts <- phyloseq_to_deseq2(surf_ps_min, design = ~days) 

surf_deseq <-  DESeq(surf_deseq_counts, test = "Wald", fitType = "local")
```

```{r}
surf_res <- results(surf_deseq, cooksCutoff = FALSE)
alpha <- 0.05
surf_sigtab <-  surf_res[which(surf_res$padj < alpha), ]
surf_sigtab <-  cbind(as(surf_sigtab, "data.frame"), as(tax_table(surf_ps_min)[rownames(surf_sigtab), ], "matrix"))
head(surf_sigtab)
```

```{r echo = FALSE, warning = FALSE, message = FALSE, fig.height = 8, fig.width = 14, fig.align = "center"}

surf_log2 <- surf_sigtab %>% 
  mutate(family_genus = paste(Family, Genus, sep = "/" ),
         class_order = paste(Class, Order, sep = "/")) %>% 
ggplot(., aes(x = family_genus, y = log2FoldChange, fill =
                  factor(class_order, levels = order.levels), shape = Phylum)) + 
  geom_point(color = "black",  alpha = 0.7, size = 6) + 
  custom_theme() +
  scale_shape_manual(values = c("Proteobacteria" = 21, "Bacteroidetes" = 22, "Marinimicrobia_(SAR406_clade)" = 24)) +
  scale_fill_manual(values = order.colors) +
  geom_hline(yintercept = 0, linetype = 2) +
  labs(x = expression(italic("")), y = expression(italic("log2 Fold Change")), fill = "Class/Order") +
  theme(axis.text.x = element_text(angle = -15, hjust = 0, vjust = 0.5)) +
  guides(fill = guide_legend(override.aes = list(shape = 21)), shape = F) +
  ggtitle("5 - 75 m")
```

### 100 - 200 m

```{r}

deep_ps_min <- subset_samples(ps_min, between(z, 100, 200))
deep_deseq_counts <- phyloseq_to_deseq2(deep_ps_min, design = ~days) 

deep_deseq <-  DESeq(deep_deseq_counts, test = "Wald", fitType = "local")
```

```{r}
deep_res <- results(deep_deseq, cooksCutoff = FALSE)
alpha <- 0.05
deep_sigtab <-  deep_res[which(deep_res$padj < alpha), ]
deep_sigtab <-  cbind(as(deep_sigtab, "data.frame"), as(tax_table(deep_ps_min)[rownames(deep_sigtab), ], "matrix"))
head(deep_sigtab)
```

```{r echo = FALSE, warning = FALSE, message = FALSE, fig.height = 8, fig.width = 14, fig.align = "center"}

deep_log2 <- deep_sigtab %>% 
  mutate(family_genus = paste(Family, Genus, sep = "/" ),
         class_order = paste(Class, Order, sep = "/")) %>% 
ggplot(., aes(x = family_genus, y = log2FoldChange, fill =
                  factor(class_order, levels = order.levels), shape = Phylum)) + 
  geom_point(color = "black",  alpha = 0.7, size = 6) + 
  custom_theme() +
  scale_shape_manual(values = c("Proteobacteria" = 21, "Bacteroidetes" = 22, "Marinimicrobia_(SAR406_clade)" = 24)) +
  scale_fill_manual(values = order.colors) +
  geom_hline(yintercept = 0, linetype = 2) +
  labs(x = expression(italic("Family/Genus")), y = expression(italic("log2 Fold Change")), fill = "Class/Order") +
  theme(axis.text.x = element_text(angle = -15, hjust = 0, vjust = 0.5)) +
  guides(fill = guide_legend(override.aes = list(shape = 21)), shape = F) +
  ggtitle("100 - 200 m")
```

```{r echo = FALSE, warning = FALSE, message = FALSE, fig.height = 20, fig.width = 18, fig.align = "center"}
patchwork <- all_log2 / surf_log2 / deep_log2

patchwork +  
  #plot_layout(guides = 'collect') +
  plot_annotation(tag_levels = "a") &
  theme(plot.tag = element_text(size = 22)) 
```

# Custom Table

## Generate relative abundances

Our data currently shows the relative proportion of different sequences to the total number of gene copies recovered, so we'll normalize the gene copy number

```{r}
ps_std <- transform_sample_counts(ps_min, function(x) x/sum(x))
#extract the relative abundance table and coerce into dataframe
ps_std.tab <- as(otu_table(ps_std), "matrix")
ps_std.df = as.data.frame(ps_std.tab) 
```

## Table with Rel Abund, Taxa, Sample Info 

Create a new table that combines relative abundances with the taxa table

```{r}

tax.tab <- as.matrix(read.table("~/GITHUB/naames_multiday/Input/16s/HetV1TUtax.txt", header = T, row.names = 1, check.names = F, na.strings = "", sep = "\t"))

#first coerce the taxa table into a data frame
tax.df = as.data.frame(tax.tab) 
#then combine the data frames
custom.tab <- tax.df %>% 
  rownames_to_column(., var = "asv") %>% 
  left_join(., ps_std.df %>% rownames_to_column(., var = "asv")) %>% 
  #create a new index of that combines the  class, order, family, and genus values
  mutate(#pcofg = paste(Phylum, "_", Class, "_", Order,"_", Family, "_", Genus),
         # pcof = paste(Phylum, "_", Class, "_", Order,"_", Family,),
         pco = paste(Phylum, "_", Class, "_", Order)) %>% 
  select(-c(asv:Genus)) %>% 
  # select(pcof,everything()) %>% 
  # group_by(pcof) %>% 
  select(pco,everything()) %>% 
  group_by(pco) %>% 
  summarise_at(vars(contains("NAAMES2")), sum, na.rm = T) %>% 
  ungroup()

#save the row names and then make them into the column names
colnames <- custom.tab[,1] 

#transpose the dataframe so we can merge with the sample info table
t_custom.tab <-  as.data.frame(t(custom.tab[,-1]))
# colnames(t_custom.tab) <- colnames$pcof
colnames(t_custom.tab) <- colnames$pco

#merge
sweet.tab <- t_custom.tab %>% 
  rownames_to_column(., var = "sample") %>% 
  left_join(., new.sample.tab %>% rownames_to_column(., var = "sample")) %>% 
  select(sample, Cruise:bcd, aou:days, tdaa:Lys, everything()) %>% 
  arrange(CampCN, z)


rm.groups <- sweet.tab %>% 
  select(-c(sample:Lys)) %>% 
  #remove groups that are completely absent
  .[ , colSums(.) > 0] %>% 
  #arrange by biggest contributors
  .[, order(colSums(-.))] %>% 
  bind_cols(sweet.tab %>% select(sample:Lys), .)

#calculate z-scores
mean.relabund <- rm.groups %>% 
  select(z, `Proteobacteria _ Alphaproteobacteria _ SAR11_clade`:`Verrucomicrobia _ Opitutae _ RS-B22`) %>% 
  group_by(z) %>% 
  summarise_at(vars(`Proteobacteria _ Alphaproteobacteria _ SAR11_clade`:`Verrucomicrobia _ Opitutae _ RS-B22`), mean, na.rm = T) 
```


#ASV Depth Profiles

```{r}
sar11_1a <- rm.groups %>% 
  ggplot(aes(x = z, y = `Proteobacteria _ Alphaproteobacteria _ SAR11_clade _ SAR11_Ia`, group = interaction(Date, CampCN))) +
  geom_line(aes(linetype = eddy, color = Date), size = 0.7) +
  geom_point(aes(shape = eddy, fill = Date), size = 6, color = "black", stroke = 1, alpha = 0.7) + 
  labs(x = expression(italic(paste("Depth, m"))), y = expression(italic(paste("ASV"))), colour = "", fill = "", linetype = "Eddy Location", shape = "Eddy Location") +
  scale_x_reverse(breaks = pretty_breaks(), expand = c(0,0)) +
  coord_flip() +
  scale_y_continuous(expand = c(0,0)) +
  scale_shape_manual(values = c("Core" = 21, "Outside" = 24)) +
  scale_fill_date(low = "#0db5e6", high = "#d31f2a") +
  scale_color_date(low = "#0db5e6", high = "#d31f2a") +
  guides(fill = F, color = F, shape = F, linetype = F) +
  custom_theme() +
  theme(panel.spacing.x = unit(1, "cm"),
        axis.text.x = element_text(angle = 0),
        legend.key.size = unit(1, "cm"))
```

# Heatmaps

```{r echo = FALSE, warning = FALSE, message = FALSE, fig.height = 16, fig.width = 18, fig.align = "center"}
test <- rm.groups %>% 
  # select(Date, z, `Proteobacteria _ Alphaproteobacteria _ SAR11_clade _ SAR11_Ia`:tail(names(.), 1)) %>%
  # pivot_longer(., `Proteobacteria _ Alphaproteobacteria _ SAR11_clade _ SAR11_Ia`:tail(names(.), 1), names_to = "taxa", values_to = "relabund")
  
 #  #top25 taxa
 # select(Date, z, `Proteobacteria _ Alphaproteobacteria _ SAR11_clade _ SAR11_Ia`:`Chloroflexi _ SAR202_clade _ SAR202_Clade1 _ SAR202_Clade1`) %>% 
 #  pivot_longer(., c(`Proteobacteria _ Alphaproteobacteria _ SAR11_clade _ SAR11_Ia`:`Chloroflexi _ SAR202_clade _ SAR202_Clade1 _ SAR202_Clade1`), names_to = "taxa", values_to = "relabund")

select(Date, z, `Proteobacteria _ Alphaproteobacteria _ SAR11_clade`:tail(names(.), 1)) %>%
  pivot_longer(., `Proteobacteria _ Alphaproteobacteria _ SAR11_clade`:tail(names(.), 1), names_to = "taxa", values_to = "relabund")


test %>% 
  ggplot(aes(x = Date, y = taxa)) +
  geom_tile(aes(fill = relabund), color = "white") +
  # scale_fill_gradient2(low = "#0db5e6", mid = "white", high = "#d31f2a", midpoint = 0.05 ) +
  # scale_fill_gradient(low = "#0db5e6",  high = "#d31f2a") +
  scale_fill_gradient(low = "white",high = "#0db5e6") +
facet_grid(~z)
```



# Stacked Barplots

Let’s make a stacked barplot of Phyla to get a sense of the community composition in these samples.

Since this is not a quantitative analysis, and since we have more Phyla in this dataset than we can reasonably distinguish colors, we will prune out low abundance taxa and only include Orders that contribute more than 0.5% of the relative abundance of each sample. Depending on your dataset and the taxonomic level you are depicting, you can adjust this prune parameter. In later analyses, we will of course included these taxa, but for now they will just clutter our plot.


```{r}
# melt to long format (for ggploting) 
# prune out orders below 0.5% in each sample

stack_sub_ps <- sub_ps %>%
  tax_glom(taxrank = "Order") %>%                     # agglomerate at phylum level
  transform_sample_counts(function(x) {x/sum(x)} ) %>% # Transform to rel. abundance
  psmelt() %>%                                         # Melt to long format
  filter(Abundance >= 0.005) %>%                         # Filter out low abundance taxa
  arrange(Order)                                      # Sort data frame alphabetically by Order
```

```{r echo = FALSE, warning = FALSE, message = FALSE, fig.height = 14, fig.width = 8, fig.align = "center"}

# Plot 
ggplot(stack_sub_ps, aes(x = days, y = Abundance)) + 
  facet_grid(rows = "z") +
  geom_bar(aes(fill = Order), color = "black", stat = "identity", position = "stack", width = 0.25, stroke = 1) +
 scale_fill_manual(values = cal_palette("figmtn", n = 19, type = "continuous")) +
  labs(x = "Days") +
  custom_theme() +
  guides(fill = guide_legend(reverse = TRUE, keywidth = 1, kerheight = 1)) +
  ylab("Relative Abundance (Order > 0.5%) \n") 
```





